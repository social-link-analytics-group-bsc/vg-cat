import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns


class SamplingRecords:

    def plot_distribution_comparison(self, column, original_data, subset_data, output_dir, figsize=(12, 5)):
        """
        Compara distribuciones de una columna antes y despu√©s del subset
        y guarda el gr√°fico
        """
        try:
            fig, axes = plt.subplots(1, 2, figsize=figsize)
            
            # Datos originales
            original_counts = original_data[column].value_counts(normalize=True) * 100
            original_counts.plot(kind='bar', ax=axes[0], color='skyblue', alpha=0.7)
            axes[0].set_title(f'Original\n(n={len(original_data):,})', fontweight='bold')
            axes[0].set_ylabel('Porcentaje (%)')
            axes[0].tick_params(axis='x', rotation=45)
            
            # A√±adir porcentajes en las barras
            for i, (category, percentage) in enumerate(original_counts.items()):
                axes[0].text(i, percentage + 1, f'{percentage:.1f}%', 
                            ha='center', va='bottom', fontweight='bold')
            
            # Datos del subset
            subset_counts = subset_data[column].value_counts(normalize=True) * 100
            subset_counts.plot(kind='bar', ax=axes[1], color='lightgreen', alpha=0.7)
            axes[1].set_title(f'Subset\n(n={len(subset_data):,})', fontweight='bold')
            axes[1].set_ylabel('Porcentaje (%)')
            axes[1].tick_params(axis='x', rotation=45)
            
            for i, (category, percentage) in enumerate(subset_counts.items()):
                axes[1].text(i, percentage + 1, f'{percentage:.1f}%', 
                            ha='center', va='bottom', fontweight='bold')
            
            plt.tight_layout()
            
            # Guardar gr√°fico
            filename = f"distribution_{column.replace(' ', '_').replace('/', '_')}.png"
            filepath = os.path.join(output_dir, filename)
            plt.savefig(filepath, dpi=300, bbox_inches='tight')
            plt.close()
            
            return filepath
            
        except Exception as e:
            print(f"‚ùå Error creando gr√°fico para {column}: {e}")
            plt.close()
            return None

    def analyze_distributions(self, columns_to_analyze, original_data, subset_data, output_dir):
        """
        Analiza y compara distribuciones para m√∫ltiples columnas
        Guarda gr√°ficos para cada columna
        """
        print("="*80)
        print("üìä ANALIZANDO DISTRIBUCIONES Y GUARDANDO GR√ÅFICOS")
        print("="*80)
        print(f"üìÅ Los gr√°ficos se guardar√°n en: {output_dir}")
        
        saved_plots = []
        
        for column in columns_to_analyze:
            if column in original_data.columns:
                print(f"\nüîç Analizando: {column}")
                print("-" * 40)
                
                # Calcular distribuciones
                original_dist = original_data[column].value_counts(normalize=True) * 100
                subset_dist = subset_data[column].value_counts(normalize=True) * 100
                
                # Mostrar tabla comparativa
                comparison_df = pd.DataFrame({
                    'Original (%)': original_dist.round(1),
                    'Subset (%)': subset_dist.round(1),
                    'Diferencia': (subset_dist - original_dist).round(2)
                }).fillna(0)
                
                print(comparison_df.to_string())
                
                # Crear y guardar gr√°fico comparativo
                plot_path = self.plot_distribution_comparison(column, original_data, subset_data, output_dir)
                
                if plot_path:
                    saved_plots.append(plot_path)
                    print(f"üíæ Gr√°fico guardado: {os.path.basename(plot_path)}")
                else:
                    print(f"‚ùå No se pudo guardar el gr√°fico para {column}")
                
            else:
                print(f"‚ö†Ô∏è  {column} no encontrada en el dataset")
        
        return saved_plots

    def create_stratification_column(self, data):
        """
        Crea una columna simple para estratificaci√≥n basada en las variables m√°s importantes
        """
        # Prioridad de columnas para estratificaci√≥n
        priority_columns = [
            'Any',           # A√±o - muy importante para series temporales
            'Sexe',          # G√©nero - variable fundamental
            'Detecci√≥ viol√®ncia masclista'  # Variable de resultado principal
        ]
        
        # Encontrar columnas disponibles
        available_columns = [col for col in priority_columns if col in data.columns]
        
        if not available_columns:
            return None
        
        # Crear columna de estratificaci√≥n simple
        if len(available_columns) == 1:
            strat_col = data[available_columns[0]].astype(str)
        else:
            # Usar solo las 2 primeras columnas disponibles para evitar demasiadas categor√≠as
            strat_col = data[available_columns[0]].astype(str) + "_" + data[available_columns[1]].astype(str)
        
        # Manejar categor√≠as con pocos ejemplos
        value_counts = strat_col.value_counts()
        min_count = value_counts.min()
        
        if min_count < 2:
            # Agrupar categor√≠as raras
            rare_categories = value_counts[value_counts < 2].index
            strat_col = strat_col.replace(rare_categories, 'OTRAS')
            print(f"üîß Agrupadas {len(rare_categories)} categor√≠as raras")
        
        print(f"üéØ Estratificaci√≥n: {available_columns[:2]}")
        print(f"üìä Categor√≠as: {len(strat_col.unique())}, M√≠nimo: {strat_col.value_counts().min()} casos")
        
        return strat_col

    def generate_representative_subset(self, data, target_percentage=0.1, random_state=42):
        """
        Genera un subset representativo usando estratificaci√≥n simple
        """
        print("="*80)
        print("üéØ GENERANDO SUBSET REPRESENTATIVO")
        print("="*80)
        
        target_size = int(len(data) * target_percentage)
        print(f"üéØ Target: {target_size:,} casos ({target_percentage*100:.1f}% de {len(data):,})")
        
        # Crear columna de estratificaci√≥n
        stratify_col = self.create_stratification_column(data)
        
        if stratify_col is None:
            print("‚ö†Ô∏è  No se pudo crear estratificaci√≥n. Usando muestra aleatoria.")
            return data.sample(n=target_size, random_state=random_state)
        
        # Verificar que tenemos suficientes casos para estratificaci√≥n
        min_class_size = stratify_col.value_counts().min()
        if min_class_size < 2:
            print("‚ö†Ô∏è  Categor√≠as muy peque√±as. Usando muestra aleatoria.")
            return data.sample(n=target_size, random_state=random_state)
        
        # Realizar split estratificado
        try:
            train_data, _ = train_test_split(
                data,
                train_size=target_size,
                random_state=random_state,
                stratify=stratify_col
            )
            print(f"‚úÖ Subset creado: {len(train_data):,} casos")
            return train_data
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error en estratificaci√≥n: {e}")
            print("üîÑ Usando muestra aleatoria como fallback")
            return data.sample(n=target_size, random_state=random_state)


    def apply_filter(self, df: pd.DataFrame, vars_subset1: pd.DataFrame, vars_subset2: pd.DataFrame) -> pd.DataFrame:
        """
        Funci√≥n principal con tama√±o de subset muy reducido para an√°lisis estad√≠sticos √≥ptimos
        """
        # Crear directorio de salida
        output_dir = "./subset_analysis"
        os.makedirs(output_dir, exist_ok=True)
        
        print("="*80)
        print("üîç CREANDO SUBSET REPRESENTATIVO - TAMA√ëO √ìPTIMO")
        print("="*80)
        
        # Calcular tama√±o √≥ptimo basado en el dataset original
        original_size = len(df)
        
        # ESTRATEGIA MUY CONSERVADORA - √ìPTIMA PARA CHI-CUADRADO
        if original_size > 500000:
            target_percentage = 0.007  # 0.7% ‚Üí ~5,000 casos
            reason = "Muy grande (>500K) - √≥ptimo para chi-cuadrado"
        elif original_size > 100000:
            target_percentage = 0.01   # 1% ‚Üí ~7,000 casos
            reason = "Grande (>100K) - excelente para tests"
        else:
            target_percentage = 0.02   # 2% para datasets m√°s peque√±os
            reason = "Mediano/peque√±o - buen balance"
        
        target_size = int(original_size * target_percentage)
        
        print(f"üìä Estrategia de muestreo: {reason}")
        print(f"üéØ Target optimizado: {target_size:,} casos ({target_percentage*100:.1f}%)")
        print(f"üí° Justificaci√≥n: Tama√±o √≥ptimo para tests chi-cuadrado - evita potencia excesiva")
        
        # Columnas para an√°lisis
        analysis_columns = [
            'Any', 'Sexe', 'Edat', 'Tipus de fam√≠lia', 'Comarca',
            'Detecci√≥ viol√®ncia masclista', 'Viol√®ncia f√≠sica', 
            'Viol√®ncia psicol√≤gica', 'Servei que at√©n'
        ]
        
        # Filtrar columnas disponibles
        available_columns = [col for col in analysis_columns if col in df.columns]
        print(f"üìã Analizando {len(available_columns)} columnas")
        
        # Generar subset con tama√±o optimizado
        representative_subset = self.generate_representative_subset(
            data=df,
            target_percentage=target_percentage,
            random_state=42
        )
        
        # Analizar distribuciones y guardar gr√°ficos
        print("\n" + "="*80)
        print("üìà COMPARANDO DISTRIBUCIONES")
        print("="*80)
        
        saved_plots = self.analyze_distributions(
            columns_to_analyze=available_columns,
            original_data=df,
            subset_data=representative_subset,
            output_dir=output_dir
        )
        
        # Resumen final con evaluaci√≥n estad√≠stica detallada
        print("\n" + "="*80)
        print("üéØ RESUMEN FINAL - EVALUACI√ìN ESTAD√çSTICA")
        print("="*80)
        
        final_size = len(representative_subset)
        print(f"üìä Dataset original: {original_size:,} casos")
        print(f"üìä Subset creado: {final_size:,} casos")
        print(f"üìä Porcentaje: {final_size/original_size*100:.2f}%")
        print(f"üìà Gr√°ficos guardados: {len(saved_plots)}")
        
        # Evaluaci√≥n estad√≠stica detallada
        print(f"\nüî¨ EVALUACI√ìN ESTAD√çSTICA DETALLADA:")
        
        if final_size > 20000:
            assessment = "‚ùå EXCESIVO"
            power_note = "Potencia > 0.99 para efectos muy peque√±os (œÜ < 0.05)"
            recommendation = "Reducir a 5,000-10,000 casos"
            chi2_note = "Chi-cuadrado detectar√° diferencias triviales como significativas"
            
        elif final_size > 10000:
            assessment = "‚ö†Ô∏è  ALTO"
            power_note = "Potencia ~0.95-0.99 para efectos peque√±os (œÜ = 0.1)"
            recommendation = "Adecuado para an√°lisis complejos, pero a√∫n potencia alta"
            chi2_note = "Bueno para detectar efectos peque√±os-moderados"
            
        elif final_size > 5000:
            assessment = "‚úÖ √ìPTIMO"
            power_note = "Potencia ~0.80-0.90 para efectos peque√±os-moderados (œÜ = 0.1-0.2)"
            recommendation = "Excelente para la mayor√≠a de aplicaciones"
            chi2_note = "Ideal para chi-cuadrado - detecta efectos relevantes"
            
        elif final_size > 2000:
            assessment = "‚úÖ ADECUADO"
            power_note = "Potencia ~0.70-0.80 para efectos moderados (œÜ = 0.2)"
            recommendation = "Bueno para an√°lisis exploratorios"
            chi2_note = "Adecuado para efectos moderados-grandes"
            
        else:
            assessment = "‚ö†Ô∏è  PEQUE√ëO"
            power_note = "Potencia < 0.70 para efectos peque√±os"
            recommendation = "Solo para an√°lisis preliminares"
            chi2_note = "Puede faltar potencia para efectos peque√±os"
        
        print(f"   ‚Ä¢ Evaluaci√≥n: {assessment}")
        print(f"   ‚Ä¢ Tama√±o: {final_size:,} casos")
        print(f"   ‚Ä¢ Potencia: {power_note}")
        print(f"   ‚Ä¢ Chi-cuadrado: {chi2_note}")
        print(f"   ‚Ä¢ Recomendaci√≥n: {recommendation}")
        
        # Mostrar archivos guardados
        if saved_plots:
            print("\nüìÅ Archivos de gr√°ficos guardados:")
            for plot_path in saved_plots:
                print(f"   üìÑ {os.path.basename(plot_path)}")
        
        # Proporciones clave con mayor precisi√≥n
        print("\nüîç PROPORCIONES CLAVE:")
        if 'Sexe' in df.columns:
            orig_women = (df['Sexe'] == 'Dones').mean() * 100
            subset_women = (representative_subset['Sexe'] == 'Dones').mean() * 100
            diff = subset_women - orig_women
            print(f"   üë© Mujeres: {orig_women:.2f}% ‚Üí {subset_women:.2f}% (Œî{diff:+.3f}p.p.)")
        
        if 'Detecci√≥ viol√®ncia masclista' in df.columns:
            orig_violence = (df['Detecci√≥ viol√®ncia masclista'] == 'S√≠').mean() * 100
            subset_violence = (representative_subset['Detecci√≥ viol√®ncia masclista'] == 'S√≠').mean() * 100
            diff = subset_violence - orig_violence
            print(f"   üîç Violencia detectada: {orig_violence:.2f}% ‚Üí {subset_violence:.2f}% (Œî{diff:+.3f}p.p.)")
        
        # Calcular diferencia m√°xima en proporciones clave
        max_diff = 0
        for col in ['Sexe', 'Detecci√≥ viol√®ncia masclista']:
            if col in df.columns:
                orig = (df[col] == 'Dones').mean() * 100 if col == 'Sexe' else (df[col] == 'S√≠').mean() * 100
                subset_val = (representative_subset[col] == 'Dones').mean() * 100 if col == 'Sexe' else (representative_subset[col] == 'S√≠').mean() * 100
                diff = abs(subset_val - orig)
                if diff > max_diff:
                    max_diff = diff
        
        print(f"   üìè M√°xima diferencia: {max_diff:.3f}p.p.")
        
        # Guardar subset como CSV
        subset_path = os.path.join(output_dir, "representative_subset.csv")
        try:
            representative_subset.to_csv(subset_path, index=False)
            print(f"\nüíæ Subset guardado en: {subset_path}")
        except Exception as e:
            print(f"‚ùå Error guardando subset: {e}")
        
        # Guardar resumen estad√≠stico detallado
        summary_path = os.path.join(output_dir, "statistical_assessment.txt")
        try:
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write("EVALUACI√ìN ESTAD√çSTICA - SUBSET REPRESENTATIVO\n")
                f.write("=" * 60 + "\n\n")
                f.write(f"Fecha: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Dataset original: {original_size:,} casos\n")
                f.write(f"Subset creado: {final_size:,} casos\n")
                f.write(f"Porcentaje: {final_size/original_size*100:.3f}%\n\n")
                
                f.write("EVALUACI√ìN ESTAD√çSTICA:\n")
                f.write(f"- Evaluaci√≥n: {assessment}\n")
                f.write(f"- Tama√±o: {final_size:,} casos\n")
                f.write(f"- Potencia: {power_note}\n")
                f.write(f"- Chi-cuadrado: {chi2_note}\n")
                f.write(f"- Recomendaci√≥n: {recommendation}\n\n")
                
                f.write("PROPORCIONES CLAVE:\n")
                if 'Sexe' in df.columns:
                    orig_women = (df['Sexe'] == 'Dones').mean() * 100
                    subset_women = (representative_subset['Sexe'] == 'Dones').mean() * 100
                    f.write(f"- Mujeres: {orig_women:.3f}% ‚Üí {subset_women:.3f}%\n")
                
                if 'Detecci√≥ viol√®ncia masclista' in df.columns:
                    orig_violence = (df['Detecci√≥ viol√®ncia masclista'] == 'S√≠').mean() * 100
                    subset_violence = (representative_subset['Detecci√≥ viol√®ncia masclista'] == 'S√≠').mean() * 100
                    f.write(f"- Violencia detectada: {orig_violence:.3f}% ‚Üí {subset_violence:.3f}%\n")
                
                f.write(f"- M√°xima diferencia: {max_diff:.3f} p.p.\n\n")
                
                f.write("RECOMENDACIONES PARA AN√ÅLISIS CHI-CUADRADO:\n")
                if final_size <= 5000:
                    f.write("- Tama√±o adecuado para efectos moderados (œÜ > 0.2)\n")
                    f.write("- Buen balance entre potencia y especificidad\n")
                    f.write("- Resultados m√°s interpretables\n")
                else:
                    f.write("- Considerar ajustar nivel de significancia (ej: Œ± = 0.01)\n")
                    f.write("- Interpretar tama√±os de efecto (V de Cramer) en lugar de solo p-valores\n")
                    f.write("- Las diferencias peque√±as pueden ser estad√≠sticamente significativas\n")
            
            print(f"üìä Evaluaci√≥n estad√≠stica guardada en: {summary_path}")
        except Exception as e:
            print(f"‚ùå Error guardando evaluaci√≥n: {e}")
        
        return representative_subset